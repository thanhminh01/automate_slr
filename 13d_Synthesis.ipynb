{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bc2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"Your_GPT_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dokument import Dokument\n",
    "from synthesis import Synthesis\n",
    "\n",
    "import pickle\n",
    "# load your Synthesis object with existing .topic and .eligible_documents attributes\n",
    "with open(\"synthesis_task.pkl\", \"rb\") as file:\n",
    "    synthesis_task = pickle.load(file)\n",
    "print(\"Research topic to be synthesized: \", synthesis_task.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for the coding of thematic analysis of the research topic\n",
    "code_template = (\"\"\"\n",
    "Consider the research topic:\n",
    "{topic}\n",
    "\n",
    "And the text input from a publication:\n",
    "Text inputs:\n",
    "{docs}\n",
    "\n",
    "Please perform the following tasks of the coding step for a thematic analysis of the research topic:\n",
    "\n",
    "Identify and Assign Codes:\n",
    "For each segment of text that is relevant to the research topic, identify and assign a code.\n",
    "Provide Code Details:\n",
    "For each code, output the following information:\n",
    "\n",
    "Code Name: A concise, descriptive name for the code.\n",
    "Code Definition: A brief explanation of what the code represents.\n",
    "Example: A quote or excerpt that exemplifies the code name and definition.\n",
    "\n",
    "Example Output 1:\n",
    "**Code Name**: Product Quality\n",
    "**Code Definition**: Describes the perceived value and performance of a product.\n",
    "**Example**: Many reviews highlighted the excellent build quality and durability of the product.\n",
    "\n",
    "Example Output 2:\n",
    "**Code Name**: User Feedback\n",
    "**Code Definition**: \"Encompasses comments and suggestions provided by users to improve the product or service.\n",
    "**Example**: \"Users suggested adding more customization options to enhance their experience.\n",
    "\"\"\")\n",
    "\n",
    "# Format the template with the specific research topic and placeholder string for document text\n",
    "code_template_formatted = code_template.format(topic=synthesis_task.topic, docs=\"{docs}\")\n",
    "\n",
    "# Create a Prompt Template using the formatted code template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "codes_prompt = ChatPromptTemplate.from_template(code_template_formatted)\n",
    "\n",
    "# Define the language model with 0 temperature\n",
    "from langchain_openai import ChatOpenAI\n",
    "gpt4_model = ChatOpenAI(temperature=0, model_name=\"gpt-4-0125-preview\")\n",
    "\n",
    "# Define output parser to handle output\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Final chain for determining eligibility\n",
    "codes_chain = codes_prompt | gpt4_model | str_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to process and assign codes using list of eligible documents input\n",
    "async def codes_from_raw_data(dokument_list):\n",
    "    # Create list of raw data from the document list for input to the chain\n",
    "    raw_data_list = [doc.raw_data for doc in dokument_list]\n",
    "    \n",
    "    # Run the codes chain on the input\n",
    "    codes_list = await codes_chain.abatch(raw_data_list)\n",
    "    \n",
    "    # Assign the results to each document and print the codes\n",
    "    for i in range(len(dokument_list)):\n",
    "        # Save the coded data to the documents in the list\n",
    "        dokument_list[i].codes = codes_list[i]\n",
    "        print(f\"Document {i+1}:\")\n",
    "        print(\"Codes:\", dokument_list[i].codes)\n",
    "        print(\"-\" * 30)  # Separator\n",
    "\n",
    "# Usage: Run the function on the list of eligible documents\n",
    "await codes_from_raw_data(synthesis_task.eligible_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a string variable to be used as input to the determine themes\n",
    "full_codes_output = \"\"\n",
    "\n",
    "# Iterate over each eligible document to append its codes to the output variable\n",
    "for i in range(len(synthesis_task.eligible_documents)):\n",
    "    full_codes_output += f\"Document {i+1}:\\n\"\n",
    "    full_codes_output += f\"Codes: {synthesis_task.eligible_documents[i].codes}\\n\"\n",
    "    full_codes_output += \"-\" * 30 + \"\\n\"  # Add a separator for better readability\n",
    "\n",
    "# Count number of tokens in the accumulated codes output\n",
    "num_tokens = gpt4_model.get_num_tokens(full_codes_output)\n",
    "\n",
    "# Check if the number of tokens exceeds the model's limit and print debug message\n",
    "if num_tokens > 128000:\n",
    "    print(\"The output is too long for this model.\")\n",
    "else:\n",
    "    print(full_codes_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for identifying themes from coded data that are relevant to the research topic\n",
    "themes_template = (\"\"\"\n",
    "You will receive input of all coded data from a list of research documents, which contains coded \n",
    "segments of text, and a research topic. For the process of a thematic analysis of the research topic,\n",
    "identify overarching themes that encapsulate common patterns present across the coded segments related to\n",
    "the research topic, properly describe the theme as a synthesis of the data that formed the theme and\n",
    "keep tract of the source of the theme\n",
    "\n",
    "Refer to the examples to form your answers\n",
    "Example research topic: How do customers feel about various aspects of our restaurant chain?\n",
    "\n",
    "Example output 1:\n",
    "**Theme 1**: Customer has mixed feelings about the quality of the product\n",
    "**Description**: Product quality is unclear, people seem to have mixed opinion which is something we really\n",
    "should prioritize improving\n",
    "**Source**: Document 1,5,6,12,15,30....\n",
    "\n",
    "Example output 2:\n",
    "**Theme 2**: Price is good, service is bad\n",
    "**Description**\n",
    "**Source**: Document 2,5,10,25,30...\n",
    "\n",
    "** Example ends here ** \n",
    "You will now receive the researc topic and the coded data input:\n",
    "Consider the research topic: {topic}\n",
    "Coded data input:\n",
    "{docs}\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Format the template with the specified research topic and a placeholder string for the coded data input\n",
    "themes_template_formatted = themes_template.format(topic=synthesis_task.topic, docs=\"{docs}\")\n",
    "\n",
    "# Create a Prompt Template using the formatted template\n",
    "themes_prompt = ChatPromptTemplate.from_template(themes_template_formatted)\n",
    "\n",
    "# Final chain for identifying themes of the documents\n",
    "themes_chain = themes_prompt | gpt4_model | str_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke chain to synthesize a list of themes based on the codes\n",
    "synthesis_task.themes = themes_chain.invoke(full_codes_output)\n",
    "print(synthesis_task.themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results into a new file with added \"_finished\" to file name\n",
    "with open(\"synthesis_task_finished.pkl\", \"wb\") as file:\n",
    "    pickle.dump(synthesis_task, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b3b74",
   "metadata": {},
   "source": [
    "Optional: The codes of individual documents and themes list can now be viewed by running this script from this point onward, without having to run from the beginning of this .ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dokument import Dokument\n",
    "from synthesis import Synthesis\n",
    "\n",
    "# load your Synthesis object with existing .topic and .eligible_documents attribute\n",
    "with open(\"synthesis_task_finished.pkl\", \"rb\") as file:\n",
    "    synthesis_task_result = pickle.load(file)\n",
    "print(\"Research topic is:\", synthesis_task_result.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99935099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of document to view codes from\n",
    "index = 20\n",
    "print(\"Codes of Document\", index, \"with DOI\", synthesis_task_result.eligible_documents[index].DOI, \":\")\n",
    "print(synthesis_task_result.eligible_documents[index].codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Themes of Documents\", index, \"with DOI\", synthesis_task_result.eligible_documents[index].DOI, \":\")\n",
    "print(synthesis_task_result.themes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
