{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"Your_GPT_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dokument import Dokument\n",
    "import pickle\n",
    "\n",
    "# Load document list\n",
    "with open(\"dokument_list.pkl\", \"rb\") as file:\n",
    "    dokument_list = pickle.load(file)\n",
    "print(\"Loaded\", len(dokument_list), \"documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the template for extracting data for visualizing studies from a document\n",
    "extract_data_template = \"\"\"Consider the following text extracted from a document:\n",
    "{docs}\n",
    "\n",
    "For each individual study described in the document (if any), extract any data points \n",
    "that would best represent their findings. These data points will be utilized for visualization\n",
    "of the study.\n",
    "\"\"\"\n",
    "# Create a a Prompt Template using the data extraction template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "extract_data_prompt = ChatPromptTemplate.from_template(extract_data_template)\n",
    "\n",
    "# Define the language model with 0 temperature\n",
    "from langchain_openai import ChatOpenAI\n",
    "gpt4_model = ChatOpenAI(temperature=0, model_name=\"gpt-4-0125-preview\")\n",
    "\n",
    "# Define output parser to handle output\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Final chain for data extraction\n",
    "extract_data_chain = extract_data_prompt | gpt4_model | str_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb56a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select document to extract data with index value\n",
    "index = 11\n",
    "print(dokument_list[index].DOI)\n",
    "extracted_data = extract_data_chain.invoke(dokument_list[index].raw_data)\n",
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d756ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template for visual representation Python code generation\n",
    "visualization_template = (\n",
    "\"\"\"\n",
    "Based on the following extracted data, generate Python code to create any amount of visualization \n",
    "that would best represent the studies.\n",
    "{data}\n",
    "\"\"\")\n",
    "# Create a a Prompt Template using the visualization template\n",
    "visualization_prompt = ChatPromptTemplate.from_template(visualization_template)\n",
    "\n",
    "# Final chain for visualization\n",
    "visualization_data_chain = visualization_prompt | gpt4_model | str_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain to get Python code generation visual representation for the selected document\n",
    "visualization_code = visualization_data_chain.invoke(extracted_data)\n",
    "print(visualization_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815f70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
